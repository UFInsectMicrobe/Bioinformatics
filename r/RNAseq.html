---
title: "转录组数据分析"
author: "Runhang"
date: "2019-12-31"
output: html_document
abstract: \singlespacing 
---



<p>  今天是二零一九年的最后一天，留学时光匆匆而过，研究生生涯已经过去四分之一。在这里，我把这个学期学了的转录组测序方法总结了一下，放在这里供同行参考讨论。</p>
<p><font size=6><strong>Introduction</strong> </font></p>
<ul>
<li><p>The present study is to trace pluripotency of human early embryos and embryonic stem cells by single cell RNA-seq. To this end, 4-cell embryo and Oocyte cells of human were dissociated into single cell isolation then the cDNAs library were prepared and sequenced on Illumina HiSeq2000 platform.</p></li>
<li><p>More than 30 million reads were generated in each single cell sample.</p></li>
<li><p>Three biological replicates for each cell type.</p></li>
</ul>
<p><font size=6><strong>Quality Control</strong> </font></p>
<p>After sequencing, we will have fastq file. The first thing we will do is check the quality of the sequence results.</p>
<p>Tool: fastqc (0.11.7) <br /><strong>Script: (Run the bash file in hipergator)</strong></p>
<pre class="r"><code>#!/bin/bash
#SBATCH --job-name=fastqc
#SBATCH --time=01:00:00
#SBATCH --mail-user=r.shu@ufl.edu
#SBATCH --mail-type=ALL
#SBATCH --output=fastqc.log
#SBATCH --error=fastqc.err
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --mem=20gb.   
#(Note: The command above is typically what we need include in a bash file, 
#in which you tell how many memories, how much time you request)</code></pre>
<p>module load fastqc <br />fastqc ENCFF000ESM.fastq <br />fastqc ENCFF000ESS.fastq</p>
<p><em>Results</em> <br />Once completed, we will get html files containing basic info of the fastq file such as total reads, GC content, sequence length, and most importantly the per base sequence quality (see the figure below)</p>
<p><img src="/r/fastqc.png" alt="" width="500px" height="300px"/></p>
<p>An acceptable sequencing result should have at least 20 quality score (0.01 error rate) across all bases. Score 30 stand for 0.001 error rate. When it is near the end of the reads, the quality score is below 20, so the following Trim and Filter steps are required.</p>
<p><font size=6><strong>Trim &amp; Filter</strong> </font> <br /><strong>Tool</strong>: fastx_toolkit <br />cutadapt (process both pairs at the same time, which is better for paired-end data) <br /><strong>Script</strong>: <br />module load fastx_toolkit/0.0.14 <br />fastq_quality_filter -i ENCFF000ESM.fastq -q 20 –p 50 -o ENCFF000ESM.filtered.fastq <br />fastq_quality_filter -i ENCFF000ESS.fastq -q 20 –p 50 -o ENCFF000ESS.filtered.fastq <br />fastqc ENCFF000ESM.filtered2.fastq <br />fastqc ENCFF000ESS.filtered2.fastq #get rid of reads for which 50% of the bases have quality lower that 20 fastq_quality_trimmer -i ENCFF000ESM.filtered.fastq -t 25 -l 50 -o ENCFFOOOESM.f.t.fastq fastq_quality_trimmer -i ENCFF000ESS.filtered.fastq -t 25 -l 50 -o ENCFFOOOESS.f.t.fastq #trim from the 3’ end until the quality score reach 25 and then remove reads that are shorter than 50 after trimming <br />Then we run fastqc check the quality again</p>
<p><br /> An alternative of fastx_toolkit is cutadapt <br />module load cutadapt <br />cutadapt -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC <br />-AAGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATT - -quality-base=64 -q 20 -m 50 -o ENCFF000ESM.cutadapt.fastq -p ENCFF000ESS.cutadapt.fastq ENCFF000ESM.fastq ENCFF000ESS.fastq <br />fastqc ENCFF000ESM.cutadapt.fastq <br />fastqc ENCFF000ESS.cutadapt.fastq</p>
<p><font size=6><strong>Mapping</strong> </font> <br />After sequence preprocessing, we can align sequencing reads to a reference (if we have reference genome). There are 2 options in term of mapping:</p>
<ul>
<li>Mapping against the Genome (Good option is only gene level quantification is needed)</li>
<li>Mapping against the Transcriptome (Good option with will annotated species)</li>
</ul>
<p><img src="/r/flow.png" alt="" width="400px" height="500px"/></p>
<p><br />Tools: Bowtie2 and TopHat <br /><strong>Script</strong>: <br />module load bowtie2 # build the spliced index of human genome hg38.fa file in bowtie2 <br />bowtie2-build /ufrc/mcb4325/share/Week12/hg38.fa hg38 # use the index built by bowtie2 for mapping <br />module load tophat <br />tophat2 –no-coverage-search hg38 ENCFFOOOESM.f.t.fastq ENCFFOOOESS.f.t.fastq<br />
<em>Results</em>: <br />We will get a “Tophat_results” fold with accepted_hits.bam file in it. <br />BAM file is a compression format of SAM file - Binary file; Save disk (80% compression); Indexed for efficient data access; - Easy to interconvert using SAMtools - BAM to SAM <br />samtools view -h name.bam &gt; name.sam - Sort BAM file by chromosomal coordinates <br />samtools sort name.bam name.sorted</p>
<p><font size=6><strong>Quantification</strong> </font></p>
<p><br /><strong>Method 1</strong> <br />As we already have the bam file, there is no need to assemble the reads for quantification. Again, we mapped the reads based on reference genome. Now, we quantify the reads based on reference genome (Homo_sapiens.GRCh28.86.OK.gtf file).<br />
<br />Tool: htseq; samtools <br /><strong>Scripts</strong>: <br />module load samtools <br />module load htseq <br />samtools sort -n …./Tophat_results/Embryo1/accepted_hits.bam -o sortedE1.bam <br />htseq-count -f bam -s no -i gene_id sortedE1.bam …/Homo_sapiens.GRCh38.86.OK.gtf &gt; htseq_count_E1.txt</p>
<p><em>Results</em>: <br />The result file is a txt file with Ensembl gene_id (such as ENSG0000…) and the number of counts.</p>
<p><strong>Method 2 (Assembly and then quantify)</strong> <br />We can assemble the read based on reference genome with cufflinks and then we get both genes and isoform(transcripts) FPKM file. <br />FPKM stands for Fragments Per Kilobase of transcript per Million mapped reads, which normalize the basis of gene length because the longer a read is the more count it will have. So, I think this method is better than read count.</p>
<p><font size=6> <strong>Assembly</strong> </font> <br />Tool: cufflinks <br /><strong>Script</strong>: <br />module load cufflinks <br />cufflinks –library-type fr-firststrand -o /home/r.shu/no_ref_assembly /home/r.shu/tophat_out/accepted_hits.bam <br />#tophat mapped bam file was assembled without reference <br /> OR… <br />cufflinks -g …./hg38.gtf –library-type fr-firststrand -o /home/r.shu/g_assembly /home/r.shu/tophat_out/accepted_hits.bam <br />#tophat mapped bam file was assmebled by GFT reference guide <br />#hg38 gtf file is reference genome file <br />OR… <br />cufflinks -G …/hg38.gtf –library-type fr-firststrand -o /home/r.shu/G_assembly /home/r.shu/tophat_out/accepted_hits.bam <br />#tophat mapped bam file was assembled based on transcripts existing in GFT file</p>
<p>Results: We can get gene.fpkm_tracking and isoforms.fpkm_tracking files, and importantly, we get transcripts.gtf file which can be visualized in IGV software. <br />The tacking.gtf files contain quantification info that we can read in R.</p>
<p><font size=6>De novo Assembly, then mapping and quantifying </font> <br />For study organisms that are not well annotated genome, we may want to use some algorithm to assemble the raw reads together without any reference. <br />Tool: trinity; gmap <br /><strong>Script</strong>: <br />module load trinity <br />Trinity –seqType fq –max_memory 5G –left /ufrc/mcb4325/share/Week12/UHLEN1T110_R1.fastq –right /ufrc/mcb4325/share/Week12/UHLEN1T110_R2.fastq –CPU 6 <br /># we get Trinity.fasta file from this process <br /># If we have reference genome, we can map the trinity assembly result using GMAP <br />module load gmap <br />gmap_build -D . -d hg38.GMAP /ufrc/mcb4325/share/Week12/hg38.fa <br /># -D means the directory, -d means the name of the file <br />cd trinity_out_dir <br />gmap -n 1 -t 8 -f 2 -D ../ -d hg38.GMAP Trinity.fasta &gt; Trinity.gff <br /># -f 2 indicate output format and produce .gff file <br />awk ‘{if ($3 == “exon”) print $0}’ Trinity.gff &gt; Trinity.exon.gff</p>
<p><br /> <em>Note</em>: De nova transcriptome assembly has higher sensitivity to discover novel transcripts and trans-spliced transcripts BUT not as sensitive as reference-based assembly to discover low-abundance transcripts.</p>
<p><font size=6>Differential expression analysis </font> <br />We then move to R for statistics analysis. By now, we have quantified the number of each exon or gene. Also, get the gene length and GC content txt file from Ensembl to check the bias <br />mycounts_t = read.delim(“CountData.txt”)<br />
<br />dim(mycounts) <br />head(mycounts)</p>
<p>mylength_t = read.delim(“gene_transcript_length.txt” ,as.is = TRUE) <br />dim(mylength) <br />head(mylength)</p>
<p>myGC_t = read.delim(“gene_GC_content.txt”, as.is = TRUE) <br />dim(myGC) <br />head(myGC)</p>
<div id="experimental-design" class="section level2">
<h2>Experimental design</h2>
<p>myfactors_t = data.frame(“treat” = substr(colnames(mycounts_t), start = 1, stop = 1), “time” = substr(colnames(mycounts_t), start = 3, stop = 3), “cond” = substr(colnames(mycounts_t), start = 1, stop = 3)) <br />rownames(myfactors_t) = colnames(mycounts) <br />head(myfactors_t) <br />myfactors_t</p>
</div>
<div id="loading-r-libraries-to-be-used" class="section level2">
<h2>Loading R libraries to be used</h2>
<p>if (!requireNamespace(“BiocManager”, quietly = TRUE)) install.packages(“BiocManager”) <br />BiocManager::install(“EDASeq”, version = “3.8”) <br />BiocManager::install(“NOISeq”, version = “3.8”) <br />library(NOISeq) <br />library(EDASeq)</p>
<p><em>Note: As the read length and GC content bias is common in Illumina sequencing, where longer read get more counts (FPKM) and low GC content get lower counts. </em></p>
<p><strong>BIAS ANALYSIS with NOISeq</strong> ######################## # Preparing data for NOISeq package <br />mydata = NOISeq::readData(data = mycounts, factors = myfactors, gc = myGC, length = mylength)</p>
</div>
<div id="length-bias" class="section level2">
<h2>Length bias</h2>
<p><br />mylengthbias = dat(mydata, factor = “cond”, norm = FALSE, type = “lengthbias”) <br />par(mfrow = c(1,2)) <br />explo.plot(mylengthbias, samples = 1) <br />explo.plot(mylengthbias, samples = 1:8)</p>
</div>
<div id="gc-content-bias" class="section level2">
<h2>GC content bias</h2>
<p>myGCbias = dat(mydata, factor = “cond”, norm = FALSE, type = “GCbias”) <br />par(mfrow = c(1,2)) <br />explo.plot(myGCbias, samples = 1) <br />explo.plot(myGCbias, samples = 1:8)</p>
<p><img src="/r/bias.png" alt="" width="800px" height="500px"/></p>
</div>
<div id="rna-composition" class="section level2">
<h2>RNA composition</h2>
<p>mycomp = dat(mydata, norm = FALSE, type = “cd”) par(mfrow = c(1,2)) explo.plot(mycomp, samples = 1:12) explo.plot(mycomp, samples = 13:24)</p>
</div>
<div id="normalization" class="section level1">
<h1>NORMALIZATION</h1>
</div>
<div id="first-we-remove-genes-with-0-counts-in-all-samples" class="section level1">
<h1>First we remove genes with 0 counts in all samples</h1>
<p>mycounts_t = mycounts_t[rowSums(mycounts_t) &gt; 0, ]</p>
<div id="discarding-genes-without-gc-content-information" class="section level2">
<h2>Discarding genes without GC content information</h2>
<p>genesWithGC_t = intersect(rownames(mycounts_t), myGC_t[,“gene”]) myGC_t = myGC_t[myGC_t[,“gene”] %in% genesWithGC_t,] rownames(myGC_t) = myGC_t[,“gene”] mycounts_t = mycounts_t[myGC_t[,“gene”],]</p>
<p>head(mycounts_t) head(myfactors_t) ## Preparing data for EDASeq package edadata = newSeqExpressionSet(counts=as.matrix(mycounts_t), featureData=myGC_t[,2, drop = FALSE], phenoData=myfactors_t[,“cond”, drop = FALSE])</p>
</div>
<div id="correcting-gc-content-bias-with-edaseq-package-loess-method" class="section level2">
<h2>Correcting GC content bias with EDASeq package: loess method</h2>
<p>edadata &lt;- withinLaneNormalization(edadata,“GCcontent”, which=“full”) mynormdata = <a href="mailto:edadata@assayData$normalizedCounts">edadata@assayData$normalizedCounts</a></p>
</div>
<div id="applying-tmm-normalization-between-samples-with-noiseq-package" class="section level2">
<h2>Applying TMM normalization (between-samples) with NOISeq package</h2>
<p>mynormdata = tmm(mynormdata) head(mynormdata)</p>
</div>
<div id="checking-the-normalization-results" class="section level2">
<h2>Checking the normalization results</h2>
</div>
</div>
<div id="more-uniform-distributions-by-tmm" class="section level1">
<h1>More uniform distributions by TMM</h1>
<p>par(mfrow = c(1,2)) boxplot(log(as.matrix(mycounts+1)) ~ col(mycounts), main = “Before normalization”) boxplot(log(mynormdata+1) ~ col(mynormdata), main = “After normalization”)</p>
</div>
<div id="gc-bias-memoved" class="section level1">
<h1>GC bias memoved</h1>
<p>mydata.norm = NOISeq::readData(data = mynormdata, factors = myfactors, gc = myGC, length = mylength) myGCbias = dat(mydata.norm, factor = “cond”, norm = TRUE, type = “GCbias”) par(mfrow = c(1,2)) explo.plot(myGCbias, samples = 1) explo.plot(myGCbias, samples = 1:8)</p>
<div id="loading-r-libraries-to-be-used-1" class="section level2">
<h2>Loading R libraries to be used</h2>
<p>if (!requireNamespace(“BiocManager”, quietly = TRUE)) install.packages(“BiocManager”) BiocManager::install(“DESeq2”) BiocManager::install(“limma”) BiocManager::install(“maSigPro”) BiocManager::install(“statmod”) BiocManager::install(“edgeR”)</p>
<p>library(NOISeq) library(edgeR) library(DESeq2) library(limma) library(maSigPro) library(“edgeR”)</p>
<div id="edger-to-profile-the-differentially-expressed-genes" class="section level3">
<h3>edgeR to profile the differentially expressed genes</h3>
<div id="section" class="section level28">
<p></p>
<p>cond2compare = colnames(mycounts)[c(grep(“B_0”, colnames(mycounts)), grep(“B_6”, colnames(mycounts)))] cond2compare mygroups = rep(c(“B0”, “B6”), each = 3) mygroups</p>
</div>
</div>
<div id="edger" class="section level3">
<h3>edgeR</h3>
<p>myedgeR = DGEList(counts = mycounts[,cond2compare], group = mygroups) <br />myedgeR = calcNormFactors(myedgeR)<br />
<br />myedgeR = estimateCommonDisp(myedgeR) <br />myedgeR = estimateTagwiseDisp(myedgeR, trend = “movingave”) <br />myedgeR = exactTest(myedgeR) <br />names(myedgeR) <br />head(myedgeR$table) <br />topTags(myedgeR) <br />myedgeR_decide = decideTestsDGE(myedgeR, adjust.method = “BH”, p.value = 0.05, lfc = 0) <br />summary(myedgeR_decide) #Apart from edgeR, we can also use DESeq2 and NOIseq.</p>
<p><font size=6>Reduce the dimension by PCA plot</font></p>
<p><br />Though there are thousands of variables(gene expression) in each treatments, with Principal coordinate analysis plot, we can appreciate the similarity between two or more samples.</p>
<p><strong>Script</strong> <br />PCA&lt;-princomp(normal_data,cor = TRUE) # create my PCA plot function my_PCA_plot&lt;- function(x, main,col=rep(c(1:6),each=3)) { <br />t.var&lt;-cumsum(x<span class="math inline">\(sdev^2^/sum(x\)</span>sdev<sup>2</sup>)) <br />var.PC1&lt;-round(t.var[1]<em>100) <br />var.PC2&lt;-round((t.var[2]-t.var[1])</em>100) <br />plot(P[,1],P[,2], <br />main = main, <br />col=col, <br />cex=2, lwd=2, <br />xlim=c(min(P[,1])-0.1,max(P[,1])+0.1) , <br />ylim=range(P[,2])*1.3, <br />xlab= paste(“PC1:”,var.PC1,“% expel.var”, sep = “”), <br />ylab=paste(“PC2:”,var.PC2,“% expel.var”, sep = “”) ) <br />legend(x=0.55,y=0.6,legend=c(“Embryo”,“Oocyte”), <br />col =c(1:2),cex=1,bty=“o”,pch=1,text.font = 2,text.col = c(1:4), <br /> pt.cex = 1,pt.lwd = 2,xjust = 0.5,yjust = 0.5) } <br />apply the function I created and input the PCA dataset <br />my_PCA_plot(PCA, main= (“Gene expression of different cells”))</p>
</div>
</div>
</div>
<div id="positive-values-on-x-axis-indicate-the-data-is-not-centered" class="section level1">
<h1>positive values on x axis indicate the data is not centered</h1>
<p><br />mydata.c&lt;-t(apply(normal_data, 1, scale, scale=FALSE)) <br />colnames(mydata.c)&lt;-colnames(normal_data) <br />PCA.c&lt;-princomp(mydata.c,cor=TRUE) <br />my_PCA_plot(PCA.c, main=“Drug doses effect on genes expression of mice”)</p>
<p><img src="/r/pca.png" alt="" width="800px" height="500px"/></p>
<p><br />Top10&lt;- sort(abs(PCA.c$scores[,1]), decreasing= TRUE)[1:10] # Use scores ranking in PCA analysis as determinants for the top 10 differentially expressed genes.</p>
<p><font size=6>Enrichment and Pathway Analysis</font> <br />Tool: PaintOmics3</p>
<p>source(“<a href="http://bioconductor.org/biocLite.R" class="uri">http://bioconductor.org/biocLite.R</a>”) <br />biocLite(“NOISeq”) <br />biocLite(“goseq”) <br />biocLite(“goglm”) <br />library(NOISeq) <br />library(goseq)</p>
<p>setwd(“/Users/darson/Desktop/Genomics in R/Week 16/DataWeek16”) ### NOISeq analysis ### data &lt;- read.delim(“Differentiation.txt”, as.is = TRUE, header = TRUE, row.names = 1) # normalized data mygroups = rep(c(“P”, “D”), each = 3)</p>
<p>data.f = filtered.data(data, factor = mygroups, norm = TRUE, cv.cutoff = 200, cpm = 5) #filter low count genes mynoiseqbio = readData(data.f, factors = data.frame(“condi”=mygroups)) mynoiseqbio = noiseqbio(mynoiseqbio, norm = “n”, k = NULL, factor = “condi”, r = 30) mynoiseqbio.deg = degenes(mynoiseqbio, q = 0.99)</p>
<p>mynoiseqbio.deg &lt;- mynoiseqbio.deg[abs(mynoiseqbio.deg[“log2FC”])&gt; 0.3,]</p>
</div>
<div id="enrichment-analysis" class="section level1">
<h1>Enrichment analysis</h1>
<ul>
<li>We obtain GO and gene length from Biomart</li>
</ul>
<p>GOannot &lt;- read.delim(“mmuGO.txt”, as.is = TRUE, header = TRUE)</p>
</div>
<div id="obtain-gene-length" class="section level1">
<h1>Obtain gene length</h1>
<p>mmuLength &lt;- read.delim(“mmuLength.txt”, as.is = TRUE, header = TRUE)</p>
<p>mmuLength &lt;- tapply(mmuLength[,3],mmuLength[,1], median)</p>
</div>
<div id="preparing-data-for-goseq-analysis" class="section level1">
<h1>Preparing data for GOseq analysis</h1>
<p>mygenes = rownames(data.f) mmuLength = mmuLength[mygenes] NOISeq.DE = as.integer(mygenes %in% rownames(mynoiseqbio.deg)) # logical vector of DE names(NOISeq.DE) = mygenes head (NOISeq.DE,10)</p>
<div id="goseq" class="section level2">
<h2>GOseq</h2>
<p>mipwf &lt;- nullp(NOISeq.DE, bias.data = mmuLength) <br />walle &lt;- goseq(pwf = mipwf, gene2cat = GOannot, method = “Wallenius”, repcnt = 2000) <br />enriched &lt;- walle<span class="math inline">\(category[walle\)</span>over_represented_pvalue&lt; 0.01] <br />GO.enriched &lt;- GOannot[match(enriched, GOannot[,2]),3] # obtain GO names <br />head (GO.enriched, 30) # GO results <br />tail (GO.enriched, 30) # GO results</p>
</div>
</div>
<div id="prepare-data-for-paintomics" class="section level1">
<h1>Prepare data for Paintomics</h1>
<p>mynoiseqbio.all = degenes(mynoiseqbio, q = 0) <br />expr.data &lt;- cbind (name = rownames(mynoiseqbio.all), FC = mynoiseqbio.all[,“log2FC”]) <br />write.table( expr.data, “expr.data.txt”, row.names = F, col.names = T, quote = F, sep = “” ) <br />write.table(rownames(mynoiseqbio.deg), “DE.data.txt”, row.names = F, col.names = F, quote = F, sep = “” )</p>
<p>Upload expr.data and DE.data.txt files in PaintOmics</p>
<p><img src="/r/paintomics.png" alt="" width="800px" height="500px"/></p>
</div>
